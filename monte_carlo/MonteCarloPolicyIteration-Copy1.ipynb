{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b81cd9-f0aa-4969-ba12-da72e793274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5667078-06fe-4f3a-9c56-559cef20a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfe41219-772c-4646-ae10-b5d4ac71d405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.delta = []\n",
    "        self.delta_p = []\n",
    "        self.cards = [1,2,3,4,5,6,7,8,9,10]\n",
    "        \n",
    "        # Set of state\n",
    "        self.set_of_states = {\n",
    "            \"dealer_showing\": (1,10),\n",
    "            \"player_sum\": (12,21),\n",
    "            \"usable_ace\": (0,1),\n",
    "        }\n",
    "        # Value function\n",
    "        self.V = np.zeros((   \n",
    "            self.set_of_states[\"dealer_showing\"][1]-self.set_of_states[\"dealer_showing\"][0]+1,\n",
    "            self.set_of_states[\"player_sum\"][1]-self.set_of_states[\"player_sum\"][0]+1,\n",
    "            self.set_of_states[\"usable_ace\"][1]-self.set_of_states[\"usable_ace\"][0]+1))\n",
    "        \n",
    "        # State-Action function\n",
    "        self.Q = np.random.random((   \n",
    "            self.set_of_states[\"dealer_showing\"][1]-self.set_of_states[\"dealer_showing\"][0]+1,\n",
    "            self.set_of_states[\"player_sum\"][1]-self.set_of_states[\"player_sum\"][0]+1,\n",
    "            self.set_of_states[\"usable_ace\"][1]-self.set_of_states[\"usable_ace\"][0]+1,\n",
    "            2\n",
    "        ))+2\n",
    "        \n",
    "        self.policy = np.random.choice([0,1],(   \n",
    "            self.set_of_states[\"dealer_showing\"][1]-self.set_of_states[\"dealer_showing\"][0]+1,\n",
    "            self.set_of_states[\"player_sum\"][1]-self.set_of_states[\"player_sum\"][0]+1,\n",
    "            self.set_of_states[\"usable_ace\"][1]-self.set_of_states[\"usable_ace\"][0]+1))\n",
    "        #self.policy[:,-2:,:] = 1\n",
    "        self.N = np.zeros(self.Q.shape)\n",
    "        \n",
    "        self.gamma = 1\n",
    "        \n",
    "        self.NV = np.zeros(self.V.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def iterate_policy(self, episodes):\n",
    "        \n",
    "        for i in range(episodes):\n",
    "            Q_bkup = self.Q.copy()\n",
    "            P_bkup = self.policy.copy()\n",
    "            \n",
    "            dfc = np.random.choice(self.cards)\n",
    "            state_0 = (dfc, 11 + np.random.choice(self.cards), np.random.choice(2))\n",
    "            action_0 = np.random.choice(2)\n",
    "            \n",
    "            states, rewards, actions = self.generate_episode(initial_action=action_0,initial_state=state_0)\n",
    "            \n",
    "            \n",
    "            G = 0\n",
    "            for t in range(0,len(states))[::-1]:\n",
    "                G = self.gamma * G + rewards[t]\n",
    "                \n",
    "                #print(f\"G:{G}\")\n",
    "                case_pos = (states[t][0]-self.set_of_states[\"dealer_showing\"][0],states[t][1]-self.set_of_states[\"player_sum\"][0],states[t][2]-self.set_of_states[\"usable_ace\"][0])\n",
    "                \n",
    "                self.N[case_pos[0]][case_pos[1]][case_pos[2]][int(actions[t])] += 1\n",
    "                self.Q[case_pos[0]][case_pos[1]][case_pos[2]][int(actions[t])] += (G-self.Q[case_pos[0]][case_pos[1]][case_pos[2]][int(actions[t])]) /self.N[case_pos[0]][case_pos[1]][case_pos[2]][int(actions[t])]\n",
    "                self.policy = np.argmax(self.Q,axis=-1)\n",
    "                \n",
    "                \n",
    "            self.delta.append(np.sum(np.abs(Q_bkup-self.Q)))\n",
    "            self.delta_p.append(np.sum(np.abs(P_bkup-self.policy)))\n",
    "            \n",
    "    \n",
    "    def aproximateV(self,episodes):\n",
    "        for i in tqdm(range(episodes)):\n",
    "            states, rewards, actions = self.generate_episode()\n",
    "            G = 0\n",
    "            for t in range(0,len(states))[::-1]:\n",
    "                \n",
    "                G = self.gamma * G + rewards[t]\n",
    "                #print(states[t])\n",
    "                case_pos = (states[t][0]-self.set_of_states[\"dealer_showing\"][0],states[t][1]-self.set_of_states[\"player_sum\"][0],states[t][2]-self.set_of_states[\"usable_ace\"][0])\n",
    "                \n",
    "                self.NV[case_pos[0]][case_pos[1]][case_pos[2]] += 1\n",
    "                self.V[case_pos[0]][case_pos[1]][case_pos[2]] += (G-self.V[case_pos[0]][case_pos[1]][case_pos[2]]) /self.NV[case_pos[0]][case_pos[1]][case_pos[2]]\n",
    "                \n",
    "            \n",
    "            \n",
    "    def generate_episode(self, initial_action = None, initial_state = None):\n",
    "        \n",
    "        if initial_state == None:\n",
    "            dfc = np.random.choice(self.cards)\n",
    "            state = (dfc, 11 + np.random.choice(self.cards), 1)\n",
    "        else:\n",
    "            state = initial_state\n",
    "            \n",
    "        dealer_sum = state[0] + np.random.choice(self.cards)\n",
    "            \n",
    "        states = []\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        \n",
    "        while True:\n",
    "            states.append(state)\n",
    "            state,r,dealer_sum,a = self.transition_model(state, dealer_sum,action = initial_action)\n",
    "            initial_action = None\n",
    "            \n",
    "            actions.append(a)\n",
    "            rewards.append(r)\n",
    "            \n",
    "            \n",
    "            if state[0] == -1:\n",
    "                break\n",
    "                \n",
    "        return states, rewards, actions\n",
    "                \n",
    "                \n",
    "    def transition_model(self, state, dealer_sum, action = None):\n",
    "        \n",
    "        #Player move\n",
    "        reward = 0\n",
    "        \n",
    "        if action == None:\n",
    "            action = self.policy[state[0]-self.set_of_states[\"dealer_showing\"][0],state[1]-self.set_of_states[\"player_sum\"][0],state[2]-self.set_of_states[\"usable_ace\"][0]]\n",
    "        \n",
    "        #print(f\"Action:{action}\")\n",
    "        \n",
    "        if action == 0: #take   \n",
    "            \n",
    "            player_sum = state[1] + np.random.choice(self.cards)\n",
    "            \n",
    "            if player_sum > 21 and state[2] == 1:\n",
    "                player_sum -= 10\n",
    "                next_state = (state[0],player_sum,0)\n",
    "            elif  player_sum <= 21:\n",
    "                next_state = (state[0],player_sum,state[2])\n",
    "            else:\n",
    "                #player loses\n",
    "                next_state = (-1,player_sum,-1)\n",
    "                reward = -1\n",
    "                #print(f\"Player bust\")\n",
    "                return(next_state, reward, dealer_sum,action)\n",
    "            \n",
    "        else:\n",
    "            player_sum = state[1]\n",
    "            next_state = state\n",
    "            \n",
    "        # Dealer move\n",
    "        if dealer_sum < 17:\n",
    "            dealer_sum += np.random.choice(self.cards)\n",
    "            if dealer_sum > 21:\n",
    "                next_state = (-1,player_sum,-1)\n",
    "                \n",
    "                #print(f\"Dealer bust\")\n",
    "                reward = 1\n",
    "        \n",
    "        if  self.policy[state[0]-self.set_of_states[\"dealer_showing\"][0],state[1]-self.set_of_states[\"player_sum\"][0],state[2]-self.set_of_states[\"usable_ace\"][0]] == 1 and dealer_sum <= 21: #End game\n",
    "            \n",
    "            #print(f\"No more moves\")\n",
    "            if dealer_sum > player_sum:\n",
    "                reward = -1\n",
    "            elif dealer_sum == player_sum:\n",
    "                reward = 0\n",
    "            else:\n",
    "                reward = 1\n",
    "            next_state = (-1,player_sum,-1)\n",
    "        return(next_state, reward, dealer_sum,action)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d55a11c-046f-4d57-be9c-4a91393c860d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5a0b7c90d54adc84fb5e16e6a9db8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = Model()\n",
    "ps = []\n",
    "m.iterate_policy(100000)\n",
    "a = 400\n",
    "for i in tqdm(range(a)):\n",
    "    m.iterate_policy(100)\n",
    "    ps.append(m.policy)\n",
    "\n",
    "pol = np.sum(ps,axis=0)/a\n",
    "pold = pol.copy()\n",
    "pold[pold>.5] = 1\n",
    "pold[pold<=.5] = 0\n",
    "#pol[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c53c96-7e5a-4244-b30a-4cb6527cea77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(m.delta))),m.delta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b0e1e85-3d9a-4366-86a9-119ebec82bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e269d5e23247d28265659dcee1e78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "fig.set_size_inches(5, 5)\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(12,22)\n",
    "Y = np.arange(1,11)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "ax.plot_surface(X, Y, pol[:,:,0], linewidth=0, antialiased=False,cmap=cm.plasma)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "ax.plot_surface(X, Y, pol[:,:,1], linewidth=0, antialiased=False,cmap=cm.plasma)\n",
    "\"\"\"\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(pol[:,:,0],cmap=\"gray\")\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(pol[:,:,1],cmap=\"gray\")\n",
    "\"\"\"\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91096b2f-33e9-4b65-9788-8082cf7f773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.policy = pold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ad14d9c-17ba-4488-80da-24d16516e3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9b728385c24cb4a9e9e165b6d6d001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.aproximateV(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a7872e7-1251-4fe7-bdbc-c253564e9dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b2caf2fa134afe96d851c563280584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(12,22)\n",
    "Y = np.arange(1,11)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.plot_surface(X, Y, m.V[:,:,0], linewidth=0, antialiased=False,cmap=cm.plasma)\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax.plot_surface(X, Y, m.V[:,:,1], linewidth=0, antialiased=False,cmap=cm.plasma)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68fd6a5-9618-4f6b-8ee1-e61ec4640c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
