{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d21b84-3f7f-444c-add8-dca5b4eed574",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9bd6c2-a686-4945-a4f0-dd108f5a4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c35382d-0556-49fb-aa91-451ce4b2f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.delta = []\n",
    "        self.delta_p = []\n",
    "        self.cards = [1,2,3,4,5,6,7,8,9,10]\n",
    "        \n",
    "        self.alpha = .1\n",
    "        \n",
    "        # Set of state\n",
    "        self.set_of_states = {\n",
    "            \"dealer_showing\": (1,10),\n",
    "            \"player_sum\": (12,21),\n",
    "            \"usable_ace\": (0,1),\n",
    "        }\n",
    "        # Value function\n",
    "        self.V = np.zeros((   \n",
    "            self.set_of_states[\"dealer_showing\"][1]-self.set_of_states[\"dealer_showing\"][0]+1,\n",
    "            self.set_of_states[\"player_sum\"][1]-self.set_of_states[\"player_sum\"][0]+1,\n",
    "            self.set_of_states[\"usable_ace\"][1]-self.set_of_states[\"usable_ace\"][0]+1))\n",
    "        \n",
    "        # State-Action function\n",
    "        self.Q = np.random.random((   \n",
    "            self.set_of_states[\"dealer_showing\"][1]-self.set_of_states[\"dealer_showing\"][0]+1,\n",
    "            self.set_of_states[\"player_sum\"][1]-self.set_of_states[\"player_sum\"][0]+1,\n",
    "            self.set_of_states[\"usable_ace\"][1]-self.set_of_states[\"usable_ace\"][0]+1,\n",
    "            2\n",
    "        ))+2\n",
    "        \n",
    "        self.policy = np.random.choice([0,1],(   \n",
    "            self.set_of_states[\"dealer_showing\"][1]-self.set_of_states[\"dealer_showing\"][0]+1,\n",
    "            self.set_of_states[\"player_sum\"][1]-self.set_of_states[\"player_sum\"][0]+1,\n",
    "            self.set_of_states[\"usable_ace\"][1]-self.set_of_states[\"usable_ace\"][0]+1))\n",
    "        #self.policy[:,-2:,:] = 1\n",
    "        self.N = np.zeros(self.Q.shape)\n",
    "        \n",
    "        self.gamma = 1\n",
    "        \n",
    "        self.NV = np.zeros(self.V.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def iterate_policy(self, episodes):\n",
    "        \n",
    "        for i in tqdm(range(episodes)):\n",
    "            Q_bkup = self.Q.copy()\n",
    "            P_bkup = self.policy.copy()\n",
    "            \n",
    "            dfc = np.random.choice(self.cards)\n",
    "            state_0 = (dfc, 11 + np.random.choice(self.cards), np.random.choice(2))\n",
    "            action_0 = np.random.choice(2)\n",
    "            \n",
    "            states, rewards, actions = self.generate_episode(initial_action=action_0,initial_state=state_0)\n",
    "            \n",
    "            \n",
    "            G = 0\n",
    "            for t in range(0,len(states))[::-1]:\n",
    "                G = self.gamma * G + rewards[t]\n",
    "                \n",
    "                #print(f\"G:{G}\")\n",
    "                case_pos = (states[t][0]-self.set_of_states[\"dealer_showing\"][0],states[t][1]-self.set_of_states[\"player_sum\"][0],states[t][2]-self.set_of_states[\"usable_ace\"][0])\n",
    "                #next_case_pos = (states[t+1][0]-self.set_of_states[\"dealer_showing\"][0],states[t+1][1]-self.set_of_states[\"player_sum\"][0],states[t+1][2]-self.set_of_states[\"usable_ace\"][0])\n",
    "                \n",
    "                #Q_max = self.max(self.Q[next_case_pos[0]][next_case_pos[1]][next_case_pos[2]])\n",
    "                self.Q[case_pos[0]][case_pos[1]][case_pos[2]][int(actions[t])] = self.alpha * (G) + (1-self.alpha)*self.Q[case_pos[0]][case_pos[1]][case_pos[2]][int(actions[t])]\n",
    "                \n",
    "                self.policy = np.argmax(self.Q,axis=-1)\n",
    "                \n",
    "                \n",
    "            self.delta.append(np.sum(np.abs(Q_bkup-self.Q)))\n",
    "            self.delta_p.append(np.sum(np.abs(P_bkup-self.policy)))\n",
    "            \n",
    "    \n",
    "    def aproximateV(self,episodes):\n",
    "        for i in tqdm(range(episodes)):\n",
    "            states, rewards, actions = self.generate_episode()\n",
    "            G = 0\n",
    "            for t in range(0,len(states))[::-1]:\n",
    "                \n",
    "                G = self.gamma * G + rewards[t]\n",
    "                #print(states[t])\n",
    "                case_pos = (states[t][0]-self.set_of_states[\"dealer_showing\"][0],states[t][1]-self.set_of_states[\"player_sum\"][0],states[t][2]-self.set_of_states[\"usable_ace\"][0])\n",
    "                \n",
    "                self.NV[case_pos[0]][case_pos[1]][case_pos[2]] += 1\n",
    "                self.V[case_pos[0]][case_pos[1]][case_pos[2]] += (G-self.V[case_pos[0]][case_pos[1]][case_pos[2]]) /self.NV[case_pos[0]][case_pos[1]][case_pos[2]]\n",
    "                \n",
    "            \n",
    "            \n",
    "    def generate_episode(self, initial_action = None, initial_state = None):\n",
    "        \n",
    "        if initial_state == None:\n",
    "            dfc = np.random.choice(self.cards)\n",
    "            state = (dfc, 11 + np.random.choice(self.cards), 1)\n",
    "        else:\n",
    "            state = initial_state\n",
    "            \n",
    "        dealer_sum = state[0] + np.random.choice(self.cards)\n",
    "            \n",
    "        states = []\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        \n",
    "        while True:\n",
    "            states.append(state)\n",
    "            state,r,dealer_sum,a = self.transition_model(state, dealer_sum,action = initial_action)\n",
    "            initial_action = None\n",
    "            \n",
    "            actions.append(a)\n",
    "            rewards.append(r)\n",
    "            \n",
    "            \n",
    "            if state[0] == -1:\n",
    "                break\n",
    "                \n",
    "        return states, rewards, actions\n",
    "                \n",
    "                \n",
    "    def transition_model(self, state, dealer_sum, action = None):\n",
    "        \n",
    "        #Player move\n",
    "        reward = 0\n",
    "        \n",
    "        if action == None:\n",
    "            action = self.policy[state[0]-self.set_of_states[\"dealer_showing\"][0],state[1]-self.set_of_states[\"player_sum\"][0],state[2]-self.set_of_states[\"usable_ace\"][0]]\n",
    "        \n",
    "        #print(f\"Action:{action}\")\n",
    "        \n",
    "        if action == 0: #take   \n",
    "            \n",
    "            player_sum = state[1] + np.random.choice(self.cards)\n",
    "            \n",
    "            if player_sum > 21 and state[2] == 1:\n",
    "                player_sum -= 10\n",
    "                next_state = (state[0],player_sum,0)\n",
    "            elif  player_sum <= 21:\n",
    "                next_state = (state[0],player_sum,state[2])\n",
    "            else:\n",
    "                #player loses\n",
    "                next_state = (-1,player_sum,-1)\n",
    "                reward = -1\n",
    "                #print(f\"Player bust\")\n",
    "                return(next_state, reward, dealer_sum,action)\n",
    "            \n",
    "        else:\n",
    "            player_sum = state[1]\n",
    "            next_state = state\n",
    "            \n",
    "        # Dealer move\n",
    "        if dealer_sum < 17:\n",
    "            dealer_sum += np.random.choice(self.cards)\n",
    "            if dealer_sum > 21:\n",
    "                next_state = (-1,player_sum,-1)\n",
    "                \n",
    "                #print(f\"Dealer bust\")\n",
    "                reward = 1\n",
    "        \n",
    "        if  self.policy[state[0]-self.set_of_states[\"dealer_showing\"][0],state[1]-self.set_of_states[\"player_sum\"][0],state[2]-self.set_of_states[\"usable_ace\"][0]] == 1 and dealer_sum <= 21: #End game\n",
    "            \n",
    "            #print(f\"No more moves\")\n",
    "            if dealer_sum > player_sum:\n",
    "                reward = -1\n",
    "            elif dealer_sum == player_sum:\n",
    "                reward = 0\n",
    "            else:\n",
    "                reward = 1\n",
    "            next_state = (-1,player_sum,-1)\n",
    "        return(next_state, reward, dealer_sum,action)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2415e5bf-ee4a-4b85-bc40-6c97eff26575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63c0f5aecc44df39e0ba5e880f27854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e0912f74bc7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d435a4489498>\u001b[0m in \u001b[0;36miterate_policy\u001b[0;34m(self, episodes)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m#print(f\"G:{G}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mcase_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_of_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dealer_showing\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_of_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"player_sum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_of_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usable_ace\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mnext_case_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_of_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dealer_showing\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_of_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"player_sum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_of_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usable_ace\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mQ_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_case_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_case_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_case_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "m = Model()\n",
    "m.iterate_policy(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a386bb8-597a-406c-a17b-4ef6016a965f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
