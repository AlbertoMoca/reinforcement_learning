{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b81cd9-f0aa-4969-ba12-da72e793274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5667078-06fe-4f3a-9c56-559cef20a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57ee13-f886-4f06-be07-e9aed2d09190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe41219-772c-4646-ae10-b5d4ac71d405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.cards = [1,2,3,4,5,6,7,8,9,10,10,10,10]\n",
    "        \n",
    "        # Set of state\n",
    "        self.set_of_states = {\n",
    "            \"dealer_showing\": (1,10),\n",
    "            \"player_sum\": (12,21),\n",
    "            \"usable_ace\": (0,1),\n",
    "        }\n",
    "        # Value function\n",
    "        self.V = np.zeros((   \n",
    "            self.set_of_states[\"dealer_showing\"][1]-self.set_of_states[\"dealer_showing\"][0]+1,\n",
    "            self.set_of_states[\"player_sum\"][1]-self.set_of_states[\"player_sum\"][0]+1,\n",
    "            self.set_of_states[\"usable_ace\"][1]-self.set_of_states[\"usable_ace\"][0]+1))\n",
    "        \n",
    "        # State-Action function\n",
    "        self.Q = np.random.random((   \n",
    "            self.set_of_states[\"dealer_showing\"][1]-self.set_of_states[\"dealer_showing\"][0]+1,\n",
    "            self.set_of_states[\"player_sum\"][1]-self.set_of_states[\"player_sum\"][0]+1,\n",
    "            self.set_of_states[\"usable_ace\"][1]-self.set_of_states[\"usable_ace\"][0]+1,\n",
    "            2\n",
    "        ))+2\n",
    "        \n",
    "        self.policy = np.random.choice([0,1],(   \n",
    "            self.set_of_states[\"dealer_showing\"][1]-self.set_of_states[\"dealer_showing\"][0]+1,\n",
    "            self.set_of_states[\"player_sum\"][1]-self.set_of_states[\"player_sum\"][0]+1,\n",
    "            self.set_of_states[\"usable_ace\"][1]-self.set_of_states[\"usable_ace\"][0]+1))\n",
    "        #self.policy[:,-2:,:] = 1\n",
    "        \n",
    "        self.gamma = 1\n",
    "        \n",
    "        self.Returns = []\n",
    "        \n",
    "        for i in range(self.Q.shape[0]):\n",
    "            a = []\n",
    "            for j in range(self.Q.shape[1]):\n",
    "                b = []\n",
    "                for k in range(self.Q.shape[2]):\n",
    "                    c = []\n",
    "                    for l in range(self.Q.shape[3]):\n",
    "                        c.append([])\n",
    "                    b.append(c)\n",
    "                a.append(b)\n",
    "            self.Returns.append(a)\n",
    "            \n",
    "        self.Returns_V = []\n",
    "        \n",
    "        for i in range(self.V.shape[0]):\n",
    "            a = []\n",
    "            for j in range(self.V.shape[1]):\n",
    "                b = []\n",
    "                for k in range(self.V.shape[2]):\n",
    "                    b.append([])\n",
    "                a.append(b)\n",
    "            self.Returns_V.append(a)\n",
    "        \n",
    "        \n",
    "    def iterate_policy(self, episodes):\n",
    "        \n",
    "        for i in tqdm(range(episodes)):\n",
    "            \n",
    "            dfc = np.random.choice(self.cards)\n",
    "            state_0 = (dfc, 11 + np.random.choice(self.cards), np.random.choice(2))\n",
    "            action_0 = np.random.choice(2)\n",
    "            \n",
    "            \n",
    "            states, rewards, actions = self.generate_episode(initial_action=action_0,initial_state=state_0)\n",
    "            \n",
    "            \n",
    "            G = 0\n",
    "            for t in range(0,len(states))[::-1]:\n",
    "                G = self.gamma * G + rewards[t]\n",
    "                \n",
    "                #print(f\"G:{G}\")\n",
    "                case_pos = (states[t][0]-self.set_of_states[\"dealer_showing\"][0],states[t][1]-self.set_of_states[\"player_sum\"][0],states[t][2]-self.set_of_states[\"usable_ace\"][0])\n",
    "                \n",
    "                self.Returns[case_pos[0]][case_pos[1]][case_pos[2]][int(actions[t])].append(G)\n",
    "                self.Q[case_pos[0]][case_pos[1]][case_pos[2]][int(actions[t])] = np.mean(self.Returns[case_pos[0]][case_pos[1]][case_pos[2]][int(actions[t])])\n",
    "                self.policy = np.argmax(self.Q,axis=-1)\n",
    "            \n",
    "    \n",
    "    def aproximateV(self,episodes):\n",
    "        for i in range(episodes):#tqdm(range(episodes)):\n",
    "            states, rewards, actions = self.generate_episode()\n",
    "            G = 0\n",
    "            for t in range(0,len(states))[::-1]:\n",
    "                G = self.gamma * G + rewards[t]\n",
    "                #print(states[t])\n",
    "                self.Returns_V[states[t][0]-self.set_of_states[\"dealer_showing\"][0]][states[t][1]-self.set_of_states[\"player_sum\"][0]][states[t][2]-self.set_of_states[\"usable_ace\"][0]].append(G)\n",
    "                self.V[states[t][0]-self.set_of_states[\"dealer_showing\"][0]][states[t][1]-self.set_of_states[\"player_sum\"][0]][states[t][2]-self.set_of_states[\"usable_ace\"][0]] = np.mean(self.Returns_V[states[t][0]-self.set_of_states[\"dealer_showing\"][0]][states[t][1]-self.set_of_states[\"player_sum\"][0]][states[t][2]-self.set_of_states[\"usable_ace\"][0]])\n",
    "            \n",
    "            \n",
    "            \n",
    "    def generate_episode(self, initial_action = None, initial_state = None):\n",
    "        \n",
    "        if initial_state == None:\n",
    "            dfc = np.random.choice(self.cards)\n",
    "            state = (dfc, 11 + np.random.choice(self.cards), 1)\n",
    "        else:\n",
    "            state = initial_state\n",
    "            \n",
    "        dealer_sum = state[0] + np.random.choice(self.cards)\n",
    "            \n",
    "        states = []\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        \n",
    "        while True:\n",
    "            states.append(state)\n",
    "            state,r,dealer_sum,a = self.transition_model(state, dealer_sum,action = initial_action)\n",
    "            initial_action = None\n",
    "            \n",
    "            actions.append(a)\n",
    "            rewards.append(r)\n",
    "            \n",
    "            \n",
    "            if state[0] == -1:\n",
    "                break\n",
    "                \n",
    "        return states, rewards, actions\n",
    "                \n",
    "                \n",
    "    def transition_model(self, state, dealer_sum, action = None):\n",
    "        \n",
    "        #Player move\n",
    "        reward = 0\n",
    "        \n",
    "        if action == None:\n",
    "            action = self.policy[state[0]-self.set_of_states[\"dealer_showing\"][0],state[1]-self.set_of_states[\"player_sum\"][0],state[2]-self.set_of_states[\"usable_ace\"][0]]\n",
    "        \n",
    "        #print(f\"Action:{action}\")\n",
    "        \n",
    "        if action == 0: #take   \n",
    "            \n",
    "            player_sum = state[1] + np.random.choice(self.cards)\n",
    "            \n",
    "            if player_sum > 21 and state[2] == 1:\n",
    "                player_sum -= 10\n",
    "                next_state = (state[0],player_sum,0)\n",
    "            elif  player_sum <= 21:\n",
    "                next_state = (state[0],player_sum,state[2])\n",
    "            else:\n",
    "                #player loses\n",
    "                next_state = (-1,player_sum,-1)\n",
    "                reward = -1\n",
    "                #print(f\"Player bust\")\n",
    "                return(next_state, reward, dealer_sum,action)\n",
    "            \n",
    "        else:\n",
    "            player_sum = state[1]\n",
    "            next_state = state\n",
    "            \n",
    "        # Dealer move\n",
    "        if dealer_sum < 17:\n",
    "            dealer_sum += np.random.choice(self.cards)\n",
    "            if dealer_sum > 21:\n",
    "                next_state = (-1,player_sum,-1)\n",
    "                \n",
    "                #print(f\"Dealer bust\")\n",
    "                reward = 1\n",
    "        \n",
    "        if  self.policy[state[0]-self.set_of_states[\"dealer_showing\"][0],state[1]-self.set_of_states[\"player_sum\"][0],state[2]-self.set_of_states[\"usable_ace\"][0]] == 1 and dealer_sum <= 21: #End game\n",
    "            \n",
    "            #print(f\"No more moves\")\n",
    "            if dealer_sum > player_sum:\n",
    "                reward = -1\n",
    "            elif dealer_sum == player_sum:\n",
    "                reward = 0\n",
    "            else:\n",
    "                reward = 1\n",
    "            next_state = (-1,player_sum,-1)\n",
    "        return(next_state, reward, dealer_sum,action)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55a11c-046f-4d57-be9c-4a91393c860d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db4ec1c9-86bc-439b-b79a-fc1e299b58ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214c3974e1e44a869e7fdf1f05d8a5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = Model()\n",
    "m.iterate_policy(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0e1e85-3d9a-4366-86a9-119ebec82bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cdba7561e948e8b9d442e23a41c258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "fig.set_size_inches(5, 5)\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(12,22)\n",
    "Y = np.arange(1,11)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "ax.plot_surface(X, Y, m.policy[:,:,0], linewidth=0, antialiased=False,cmap=cm.plasma)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "ax.plot_surface(X, Y, m.policy[:,:,1], linewidth=0, antialiased=False,cmap=cm.plasma)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77bb06c3-6243-47a3-a409-e712a9e3de48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e929ceda21e24612bacdd2930a89b28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(m.policy[:,:,0],cmap=\"gray\")\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(m.policy[:,:,1],cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91096b2f-33e9-4b65-9788-8082cf7f773c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad14d9c-17ba-4488-80da-24d16516e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.aproximateV(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a7872e7-1251-4fe7-bdbc-c253564e9dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1763f84bff00461fa47a092032afe532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(12,22)\n",
    "Y = np.arange(1,11)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.plot_surface(X, Y, m.V[:,:,0], linewidth=0, antialiased=False,cmap=cm.plasma)\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax.plot_surface(X, Y, m.V[:,:,1], linewidth=0, antialiased=False,cmap=cm.plasma)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68fd6a5-9618-4f6b-8ee1-e61ec4640c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
